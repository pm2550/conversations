import requests, time, json

# OpenAI GPT-3.5-turbo èŠå¤©æœºå™¨äººç±»
class OpenAIChatBot:
    def __init__(self, api_key):
        self.api_key = api_key
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        self.fine_tuned_model_id = None
        self.chat_patterns = {}
        
        # åŠ è½½èŠå¤©æ¨¡å¼åˆ†æç»“æœ
        try:
            with open('chat_patterns_final.json', 'r', encoding='utf-8') as f:
                self.chat_patterns = json.load(f)
                print(f"âœ… åŠ è½½äº†èŠå¤©æ¨¡å¼æ–‡ä»¶ï¼ŒåŒ…å« {len(self.chat_patterns)} ä¸ªæœ‹å‹çš„æ•°æ®")
        except FileNotFoundError:
            print("âš ï¸ æœªæ‰¾åˆ°èŠå¤©æ¨¡å¼æ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡å¼")
    
    def upload_training_data(self, filename="deepseek_data_final.jsonl"):
        """ä¸Šä¼ è®­ç»ƒæ•°æ®åˆ°OpenAI"""
        print(f"ğŸ“¤ ä¸Šä¼ è®­ç»ƒæ•°æ®æ–‡ä»¶: {filename}")
        
        try:
            with open(filename, "rb") as f:
                files = {"file": f}
                data = {"purpose": "fine-tune"}
                
                response = requests.post(
                    "https://api.openai.com/v1/files", 
                    headers={"Authorization": f"Bearer {self.api_key}"},
                    files=files,
                    data=data
                )
                
            if response.status_code == 200:
                file_id = response.json()["id"]
                print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼ŒID: {file_id}")
                return file_id
            else:
                print(f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶: {filename}")
            return None
        except Exception as e:
            print(f"âŒ ä¸Šä¼ è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return None
    
    def create_fine_tune(self, file_id, model="gpt-3.5-turbo", n_epochs=3):
        """åˆ›å»ºOpenAIå¾®è°ƒä»»åŠ¡"""
        print("ğŸš€ åˆ›å»ºå¾®è°ƒä»»åŠ¡...")
        payload = {
            "training_file": file_id,
            "model": model,
            "hyperparameters": {
                "n_epochs": n_epochs
            }
        }
        
        response = requests.post(
            "https://api.openai.com/v1/fine_tuning/jobs", 
            headers=self.headers, 
            json=payload
        )
        
        if response.status_code == 200:
            ft_id = response.json()["id"]
            print(f"âœ… å¾®è°ƒä»»åŠ¡åˆ›å»ºæˆåŠŸï¼ŒID: {ft_id}")
            return ft_id
        else:
            print(f"âŒ å¾®è°ƒä»»åŠ¡åˆ›å»ºå¤±è´¥: {response.status_code} - {response.text}")
            return None
    
    def wait_for_completion(self, ft_id):
        """ç­‰å¾…è®­ç»ƒå®Œæˆ"""
        print("â³ ç­‰å¾…è®­ç»ƒå®Œæˆ...")
        check_count = 0
        
        while True:
            try:
                response = requests.get(
                    f"https://api.openai.com/v1/fine_tuning/jobs/{ft_id}", 
                    headers=self.headers
                )
                
                if response.status_code == 200:
                    job_data = response.json()
                    status = job_data["status"]
                    
                    print(f"ğŸ“Š å½“å‰çŠ¶æ€: {status} (æ£€æŸ¥æ¬¡æ•°: {check_count + 1})")
                    
                    if status == "succeeded":
                        model_id = job_data.get("fine_tuned_model")
                        self.fine_tuned_model_id = model_id
                        print(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹ID: {model_id}")
                        return model_id
                    elif status == "failed":
                        error = job_data.get("error", "æœªçŸ¥é”™è¯¯")
                        print(f"âŒ è®­ç»ƒå¤±è´¥: {error}")
                        return None
                    elif status in ["cancelled", "canceled"]:
                        print("âš ï¸ è®­ç»ƒè¢«å–æ¶ˆ")
                        return None
                        
                else:
                    print(f"âš ï¸ æ£€æŸ¥çŠ¶æ€å¤±è´¥: {response.status_code}")
                    
            except Exception as e:
                print(f"âš ï¸ æ£€æŸ¥çŠ¶æ€æ—¶å‡ºé”™: {e}")
            
            check_count += 1
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    
    def generate_context_prompt(self, chat_group, conversation_history, target_friend=None):
        """æ ¹æ®èŠå¤©å¯¹è±¡å’Œå†å²ç”Ÿæˆä¸Šä¸‹æ–‡æç¤º"""
        system_content = f"ä½ æ˜¯é›·ğŸ·ğŸ·ï¼Œä¸€ä¸ªå–œæ¬¢è¯´'dds'ã€'æ„šè ¢'ã€'ä¸¢å¤§å¸ˆ'ç­‰è¯æ±‡çš„QQç¾¤èŠå¤©ç”¨æˆ·ã€‚ä½ åœ¨ç¾¤ç»„'{chat_group or 'æœªçŸ¥ç¾¤ç»„'}'ä¸­èŠå¤©ã€‚"
        
        # å¦‚æœçŸ¥é“ä¸»è¦å¯¹è¯å¯¹è±¡ï¼Œæ·»åŠ ä¸ªæ€§åŒ–ä¿¡æ¯
        if target_friend and target_friend in self.chat_patterns:
            pattern = self.chat_patterns[target_friend]
            system_content += f" ä½ æ­£åœ¨ä¸{target_friend}å¯¹è¯ï¼ˆå†å²äº’åŠ¨{pattern['interaction_count']}æ¬¡ï¼‰ã€‚"
        
        user_content = ""
        if conversation_history:
            user_content = "å¯¹è¯å†å²:\n" + "\n".join(conversation_history) + "\n\nè¯·ä»¥é›·ğŸ·ğŸ·çš„èº«ä»½å›å¤ï¼š"
        else:
            user_content = "è¯·ä»¥é›·ğŸ·ğŸ·çš„èº«ä»½å¼€å§‹å¯¹è¯ï¼š"
            
        return system_content, user_content
    
    def chat(self, chat_group, conversation_history, target_friend=None, max_tokens=50):
        """æ™ºèƒ½èŠå¤©å›å¤"""
        if not self.fine_tuned_model_id:
            print("âŒ è¯·å…ˆå®Œæˆæ¨¡å‹å¾®è°ƒ")
            return None
        
        system_content, user_content = self.generate_context_prompt(chat_group, conversation_history, target_friend)
        
        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers=self.headers,
                json={
                    "model": self.fine_tuned_model_id,
                    "messages": [
                        {"role": "system", "content": system_content},
                        {"role": "user", "content": user_content}
                    ],
                    "max_tokens": max_tokens,
                    "temperature": 0.8,
                    "stop": ["\n", ":", "ï¼š"]
                }
            )
            
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"].strip()
            else:
                print(f"âŒ ç”Ÿæˆå›å¤å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"âŒ èŠå¤©æ—¶å‡ºé”™: {e}")
            return None

# ä»é…ç½®æ–‡ä»¶è¯»å–APIå¯†é’¥
try:
    from config import OPENAI_API_KEY
    API_KEY = OPENAI_API_KEY
except ImportError:
    print("âŒ æœªæ‰¾åˆ°config.pyæ–‡ä»¶ï¼")
    print("è¯·å¤åˆ¶config_template.pyä¸ºconfig.pyå¹¶å¡«å…¥æ‚¨çš„APIå¯†é’¥")
    exit(1)

bot = OpenAIChatBot(API_KEY)

# å®Œæ•´çš„è®­ç»ƒæµç¨‹
def train_chatbot():
    """å®Œæ•´çš„è®­ç»ƒæµç¨‹"""
    print("ğŸ¯ å¼€å§‹è®­ç»ƒé›·ğŸ·ğŸ·èŠå¤©æœºå™¨äºº (ä½¿ç”¨GPT-3.5-turbo)...")
    
    # 1. ä¸Šä¼ è®­ç»ƒæ•°æ®
    file_id = bot.upload_training_data("deepseek_data_final.jsonl")
    if not file_id:
        print("âŒ è®­ç»ƒç»ˆæ­¢ï¼šæ–‡ä»¶ä¸Šä¼ å¤±è´¥")
        return None
    
    # 2. åˆ›å»ºå¾®è°ƒä»»åŠ¡
    ft_id = bot.create_fine_tune(file_id, model="gpt-3.5-turbo", n_epochs=3)
    if not ft_id:
        print("âŒ è®­ç»ƒç»ˆæ­¢ï¼šå¾®è°ƒä»»åŠ¡åˆ›å»ºå¤±è´¥")
        return None
    
    # 3. ç­‰å¾…è®­ç»ƒå®Œæˆ
    model_id = bot.wait_for_completion(ft_id)
    if model_id:
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼ç°åœ¨å¯ä»¥å¼€å§‹èŠå¤©äº†")
        
        # ä¿å­˜æ¨¡å‹ID
        with open('trained_model_id.txt', 'w') as f:
            f.write(model_id)
        print(f"ğŸ“ æ¨¡å‹IDå·²ä¿å­˜åˆ° trained_model_id.txt")
        
        return model_id
    else:
        print("âŒ è®­ç»ƒå¤±è´¥")
        return None

# æµ‹è¯•èŠå¤©
def test_chat():
    """æµ‹è¯•èŠå¤©åŠŸèƒ½"""
    if not bot.fine_tuned_model_id:
        # å°è¯•åŠ è½½ä¿å­˜çš„æ¨¡å‹ID
        try:
            with open('trained_model_id.txt', 'r') as f:
                bot.fine_tuned_model_id = f.read().strip()
            print(f"ğŸ“ åŠ è½½äº†ä¿å­˜çš„æ¨¡å‹ID: {bot.fine_tuned_model_id}")
        except:
            print("âŒ è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ")
            return
    
    # æµ‹è¯•ä¸åŒåœºæ™¯
    test_cases = [
        {
            "group": "å½“å¹´ä¸‰äººåˆ†",
            "history": ["å¯»å¸¸æ‘†æ¸¡: æ¥ä¸æ¥æˆ‘çš„ä¸–ç•Œ"],
            "friend": "å¯»å¸¸æ‘†æ¸¡"
        },
        {
            "group": "æŒ‘è¡…å¤§å¸è¡°å¾®ä¹‹å¤œ", 
            "history": ["æœé¢„: å¤ªæ„šè ¢äº†"],
            "friend": "æœé¢„"
        },
        {
            "group": "å½“å¹´ä¸‰äººåˆ†",
            "history": ["ç¥ä»™ä¼ : ä½ å¤ªæ„šè ¢äº†"],
            "friend": "ç¥ä»™ä¼ "
        }
    ]
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•èŠå¤©æ•ˆæœ...")
    for i, case in enumerate(test_cases, 1):
        print(f"\n--- æµ‹è¯•åœºæ™¯ {i} ---")
        response = bot.chat(case["group"], case["history"], case["friend"])
        print(f"ç¾¤ç»„: {case['group']}")
        print(f"å†å²: {case['history']}")
        print(f"é›·ğŸ·ğŸ·: {response}")
        print("-" * 50)

if __name__ == "__main__":
    print("ğŸ¤– OpenAI GPT-3.5-turbo èŠå¤©æœºå™¨äººè®­ç»ƒç³»ç»Ÿ")
    print("=" * 50)
    
    # ç›´æ¥å¼€å§‹è®­ç»ƒ
    print("ğŸš€ è‡ªåŠ¨å¼€å§‹è®­ç»ƒ...")
    model_id = train_chatbot()
    
    if model_id:
        print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼å¼€å§‹æµ‹è¯•èŠå¤©æ•ˆæœ...")
        test_chat()
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥")
