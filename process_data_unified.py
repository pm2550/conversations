#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€çš„èŠå¤©è®°å½•å¤„ç†è„šæœ¬
- å–æ¶ˆç¾¤ç»„ä¿¡æ¯
- å»ºç«‹IDåˆ°åå­—çš„æ˜ å°„å…³ç³»
- ç»Ÿä¸€ä½¿ç”¨æœ€å¸¸ç”¨çš„åå­—
"""

import re, json
from datetime import datetime
from collections import defaultdict, Counter

def load_blocks(path, gap_minutes=30):
    """åŠ è½½èŠå¤©è®°å½•å¹¶æŒ‰æ—¶é—´é—´éš”åˆ†ç»„ - ä¸åŒ…å«ç¾¤ç»„ä¿¡æ¯"""
    lines = [l.rstrip() for l in open(path, encoding='utf-8')]
    blocks, cur = [], []
    prev_ts = None
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # è·³è¿‡ç¾¤ç»„å’Œå¯¹è±¡ä¿¡æ¯
        if (line.startswith('æ¶ˆæ¯åˆ†ç»„:') or line.startswith('æ¶ˆæ¯å¯¹è±¡:') or 
            line.startswith('====') or 'æ¶ˆæ¯è®°å½•' in line or not line or
            line.startswith('ç³»ç»Ÿæ¶ˆæ¯')):
            i += 1
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¶é—´æˆ³è¡Œ
        timestamp_pattern = r'^(\d{4}-\d{2}-\d{2} \d{1,2}:\d{2}:\d{2})\s+'
        ts_match = re.match(timestamp_pattern, line)
        
        if ts_match:
            timestamp = ts_match.group(1)
            rest = line[ts_match.end():]
            
            # åŒ¹é…ç”¨æˆ·ä¿¡æ¯ï¼šå‘è¨€è€…(ID)
            user_match = re.match(r'(.+?)\((\d+)\)\s*$', rest)
            if user_match:
                username = user_match.group(1).strip()
                user_id = user_match.group(2)
                
                # è¯»å–æ¶ˆæ¯å†…å®¹
                message_lines = []
                j = i + 1
                
                while j < len(lines):
                    next_line = lines[j].strip()
                    
                    if re.match(timestamp_pattern, next_line):
                        break
                    if (next_line.startswith('æ¶ˆæ¯åˆ†ç»„:') or 
                        next_line.startswith('æ¶ˆæ¯å¯¹è±¡:') or 
                        next_line.startswith('====') or
                        next_line.startswith('ç³»ç»Ÿæ¶ˆæ¯')):
                        break
                    
                    message_lines.append(lines[j].rstrip())
                    j += 1
                
                message = '\n'.join(message_lines).strip()
                
                # å¤„ç†æ—¶é—´åˆ†ç»„
                try:
                    dt = datetime.fromisoformat(timestamp)
                    if prev_ts and (dt - prev_ts).total_seconds() > gap_minutes*60:
                        if cur:
                            blocks.append(cur)
                        cur = []
                    cur.append((user_id, username, message))
                    prev_ts = dt
                except:
                    pass
                
                i = j
                continue
        
        i += 1
    
    if cur:
        blocks.append(cur)
    return blocks

def build_user_mapping(blocks):
    """æ„å»ºç”¨æˆ·IDåˆ°ç»Ÿä¸€åå­—çš„æ˜ å°„å…³ç³»"""
    # ç»Ÿè®¡æ¯ä¸ªIDä½¿ç”¨çš„æ‰€æœ‰åå­—åŠå…¶é¢‘ç‡
    id_names = defaultdict(Counter)
    
    for blk in blocks:
        for user_id, username, message in blk:
            if username and user_id:
                id_names[user_id][username] += 1
    
    # ä¸ºæ¯ä¸ªIDé€‰æ‹©æœ€å¸¸ç”¨çš„åå­—
    user_mapping = {}
    for user_id, name_counts in id_names.items():
        most_common_name = name_counts.most_common(1)[0][0]
        user_mapping[user_id] = most_common_name
        
        # å¦‚æœä¸€ä¸ªIDæœ‰å¤šä¸ªåå­—ï¼Œæ‰“å°å‡ºæ¥æŸ¥çœ‹
        if len(name_counts) > 1:
            print(f"ç”¨æˆ·ID {user_id} æœ‰å¤šä¸ªåå­—: {dict(name_counts)} -> ç»Ÿä¸€ä¸º: {most_common_name}")
    
    return user_mapping

def make_unified_samples(blocks, user_mapping, target='3159852227', window=3):
    """åˆ›å»ºç»Ÿä¸€çš„è®­ç»ƒæ ·æœ¬ï¼Œä¸åŒ…å«ç¾¤ç»„ä¿¡æ¯"""
    samples = []
    user_interactions = defaultdict(list)
    
    for blk in blocks:
        for i, (uid, username, text) in enumerate(blk):
            if uid == target and text.strip():  # ç›®æ ‡ç”¨æˆ·çš„å‘è¨€
                # è·å–ä¸Šä¸‹æ–‡
                ctx = blk[max(0, i-window):i]
                
                # åˆ†æå¯¹è¯å¯¹è±¡
                conversation_partners = set()
                for c_uid, c_username, c_text in ctx:
                    if c_uid != target and c_uid in user_mapping:
                        unified_name = user_mapping[c_uid]
                        conversation_partners.add((c_uid, unified_name))
                
                # æ„å»ºmessagesæ ¼å¼çš„è®­ç»ƒæ ·æœ¬
                messages = []
                
                # ç³»ç»Ÿæ¶ˆæ¯ï¼Œä¸åŒ…å«ç¾¤ç»„ä¿¡æ¯
                system_content = "ä½ æ˜¯é›·ğŸ·ğŸ·ï¼Œä¸€ä¸ªå–œæ¬¢è¯´'dds'ã€'æ„šè ¢'ã€'ä¸¢å¤§å¸ˆ'ç­‰è¯æ±‡çš„QQç¾¤èŠå¤©ç”¨æˆ·ã€‚"
                messages.append({"role": "system", "content": system_content})
                
                # æ·»åŠ å¯¹è¯å†å²ä½œä¸ºç”¨æˆ·æ¶ˆæ¯
                if ctx:
                    context_msgs = []
                    for c_uid, c_username, c_text in ctx:
                        if c_text.strip() and c_uid in user_mapping:
                            # ä½¿ç”¨ç»Ÿä¸€çš„åå­—
                            unified_name = user_mapping[c_uid]
                            context_msgs.append(f"{unified_name}: {c_text}")
                    
                    if context_msgs:
                        user_content = "å¯¹è¯å†å²:\n" + "\n".join(context_msgs) + "\n\nè¯·ä»¥é›·ğŸ·ğŸ·çš„èº«ä»½å›å¤ï¼š"
                        messages.append({"role": "user", "content": user_content})
                
                # åŠ©æ‰‹å›å¤ï¼ˆç›®æ ‡ç”¨æˆ·çš„å®é™…å›å¤ï¼‰
                messages.append({"role": "assistant", "content": text})
                
                # åˆ›å»ºæ ·æœ¬
                sample = {
                    "messages": messages,
                    "metadata": {
                        "partners": list(conversation_partners),
                        "timestamp": blk[i][0] if i < len(blk) else None
                    }
                }
                samples.append(sample)
                
                # è®°å½•ä¸ç‰¹å®šç”¨æˆ·çš„äº’åŠ¨æ¨¡å¼
                for partner_id, partner_name in conversation_partners:
                    user_interactions[partner_name].append({
                        "context": context_msgs if 'context_msgs' in locals() else [],
                        "response": text
                    })
    
    return samples, user_interactions

def analyze_chat_patterns(user_interactions):
    """åˆ†æç”¨æˆ·å¯¹ä¸åŒæœ‹å‹çš„èŠå¤©æ¨¡å¼"""
    patterns = {}
    for friend, interactions in user_interactions.items():
        if len(interactions) >= 3:  # è‡³å°‘è¦æœ‰3æ¬¡äº’åŠ¨æ‰åˆ†æ
            responses = [inter["response"] for inter in interactions]
            
            # åˆ†æç‰¹å¾
            avg_length = sum(len(r) for r in responses) / len(responses)
            emoji_count = sum(r.count('[') + r.count('ğŸ·') + r.count('æ„šè ¢') for r in responses)
            
            patterns[friend] = {
                "interaction_count": len(interactions),
                "avg_response_length": avg_length,
                "emoji_usage": emoji_count / len(responses),
                "common_words": extract_common_words(responses)
            }
    
    return patterns

def extract_common_words(responses):
    """æå–å¸¸ç”¨è¯æ±‡"""
    words = []
    for response in responses:
        words.extend([w for w in response if len(w) > 1])
    
    return Counter(words).most_common(5)

# ä¸»å¤„ç†æµç¨‹
if __name__ == "__main__":
    print("æ­£åœ¨å¤„ç†èŠå¤©è®°å½•...")

    all_blocks = []
    for filename in ['1.txt', '2.txt']:
        print(f"å¤„ç†æ–‡ä»¶: {filename}")
        blocks = load_blocks(filename)
        print(f"  ä» {filename} è§£æå‡º {len(blocks)} ä¸ªå¯¹è¯å—")
        all_blocks.extend(blocks)

    print(f"\næ€»å…±è§£æå‡º {len(all_blocks)} ä¸ªå¯¹è¯å—")

    # æ„å»ºç”¨æˆ·æ˜ å°„
    print("\næ„å»ºç”¨æˆ·IDåˆ°åå­—çš„æ˜ å°„å…³ç³»...")
    user_mapping = build_user_mapping(all_blocks)
    print(f"å‘ç° {len(user_mapping)} ä¸ªç”¨æˆ·")

    # æ˜¾ç¤ºç›®æ ‡ç”¨æˆ·çš„åå­—
    target_user_id = '3159852227'
    if target_user_id in user_mapping:
        print(f"ç›®æ ‡ç”¨æˆ·(ID: {target_user_id})çš„ç»Ÿä¸€åå­—: {user_mapping[target_user_id]}")
    else:
        print(f"âŒ æœªæ‰¾åˆ°ç›®æ ‡ç”¨æˆ·ID: {target_user_id}")

    # ç”Ÿæˆè®­ç»ƒæ ·æœ¬
    print("\nç”Ÿæˆè®­ç»ƒæ ·æœ¬...")
    all_samples, all_interactions = make_unified_samples(all_blocks, user_mapping)

    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"æ€»å…±ç”Ÿæˆäº† {len(all_samples)} ä¸ªè®­ç»ƒæ ·æœ¬")

    # éªŒè¯æ ·æœ¬è´¨é‡
    if all_samples:
        sample = all_samples[0]
        print(f"\nğŸ“ ç¬¬ä¸€ä¸ªè®­ç»ƒæ ·æœ¬é¢„è§ˆ:")
        print(f"ç³»ç»Ÿæ¶ˆæ¯: {sample['messages'][0]['content']}")
        if len(sample['messages']) > 1:
            print(f"ç”¨æˆ·æ¶ˆæ¯: {sample['messages'][1]['content'][:100]}...")
        if len(sample['messages']) > 2:
            print(f"åŠ©æ‰‹å›å¤: {sample['messages'][2]['content'][:50]}...")

    # åˆ†æèŠå¤©æ¨¡å¼
    patterns = analyze_chat_patterns(all_interactions)
    print(f"\nğŸ‘¥ å‘ç°ä¸ {len(patterns)} ä¸ªæœ‹å‹çš„èŠå¤©æ¨¡å¼")

    # æ˜¾ç¤ºä¸»è¦å¯¹è¯ä¼™ä¼´
    if patterns:
        sorted_friends = sorted(patterns.items(), key=lambda x: x[1]['interaction_count'], reverse=True)
        print("ä¸»è¦å¯¹è¯ä¼™ä¼´:")
        for friend, data in sorted_friends[:5]:
            print(f"  - {friend}: {data['interaction_count']}æ¬¡äº’åŠ¨")

    # ä¿å­˜ç”¨æˆ·æ˜ å°„å…³ç³»
    with open('user_mapping.json', 'w', encoding='utf-8') as f:
        json.dump(user_mapping, f, ensure_ascii=False, indent=2)

    # ä¿å­˜è®­ç»ƒæ•°æ®  
    with open('deepseek_data_unified.jsonl', 'w', encoding='utf-8') as fout:
        for sample in all_samples:
            training_sample = {
                "messages": sample["messages"]
            }
            fout.write(json.dumps(training_sample, ensure_ascii=False) + '\n')

    # ä¿å­˜åˆ†æç»“æœ
    with open('chat_patterns_unified.json', 'w', encoding='utf-8') as f:
        json.dump(patterns, f, ensure_ascii=False, indent=2)

    print("\nâœ… æ•°æ®å¤„ç†å®Œæˆï¼")
    print("ç”Ÿæˆæ–‡ä»¶:")
    print("- user_mapping.json: ç”¨æˆ·IDåˆ°ç»Ÿä¸€åå­—çš„æ˜ å°„å…³ç³»")
    print("- deepseek_data_unified.jsonl: ç»Ÿä¸€åçš„è®­ç»ƒæ•°æ®ï¼ˆæ— ç¾¤ç»„ä¿¡æ¯ï¼‰")
    print("- chat_patterns_unified.json: èŠå¤©æ¨¡å¼åˆ†æ")
    print(f"\nğŸ¯ ç›®æ ‡ç”¨æˆ·({user_mapping.get(target_user_id, 'æœªçŸ¥')})çš„è®­ç»ƒæ ·æœ¬å·²å‡†å¤‡å°±ç»ªï¼") 